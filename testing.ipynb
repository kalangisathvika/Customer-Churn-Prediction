{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from collections import Counter\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.ticker as mtick \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/boppani/miniconda3/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/boppani/miniconda3/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Customer_1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>17</td>\n",
       "      <td>73.36</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer_2</td>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>48.76</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Customer_3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5</td>\n",
       "      <td>85.47</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Customer_4</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>3</td>\n",
       "      <td>97.94</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Customer_5</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>19</td>\n",
       "      <td>58.14</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID        Name  Age  Gender     Location  \\\n",
       "0           1  Customer_1   63    Male  Los Angeles   \n",
       "1           2  Customer_2   62  Female     New York   \n",
       "2           3  Customer_3   24  Female  Los Angeles   \n",
       "3           4  Customer_4   36  Female        Miami   \n",
       "4           5  Customer_5   46  Female        Miami   \n",
       "\n",
       "   Subscription_Length_Months  Monthly_Bill  Total_Usage_GB  Churn  \n",
       "0                          17         73.36             236      0  \n",
       "1                           1         48.76             172      0  \n",
       "2                           5         85.47             460      0  \n",
       "3                           3         97.94             297      1  \n",
       "4                          19         58.14             266      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df  =  pd.read_excel('customer_churn_large_dataset.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Customer_1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>17</td>\n",
       "      <td>73.36</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer_2</td>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>48.76</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Customer_3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5</td>\n",
       "      <td>85.47</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Customer_4</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>3</td>\n",
       "      <td>97.94</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Customer_5</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>19</td>\n",
       "      <td>58.14</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Customer_6</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>15</td>\n",
       "      <td>82.65</td>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Customer_7</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>3</td>\n",
       "      <td>73.79</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Customer_8</td>\n",
       "      <td>67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>1</td>\n",
       "      <td>97.70</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Customer_9</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>10</td>\n",
       "      <td>42.45</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Customer_10</td>\n",
       "      <td>53</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>12</td>\n",
       "      <td>64.49</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID         Name  Age  Gender     Location  \\\n",
       "0           1   Customer_1   63    Male  Los Angeles   \n",
       "1           2   Customer_2   62  Female     New York   \n",
       "2           3   Customer_3   24  Female  Los Angeles   \n",
       "3           4   Customer_4   36  Female        Miami   \n",
       "4           5   Customer_5   46  Female        Miami   \n",
       "5           6   Customer_6   67    Male     New York   \n",
       "6           7   Customer_7   30  Female      Chicago   \n",
       "7           8   Customer_8   67  Female        Miami   \n",
       "8           9   Customer_9   20  Female        Miami   \n",
       "9          10  Customer_10   53  Female  Los Angeles   \n",
       "\n",
       "   Subscription_Length_Months  Monthly_Bill  Total_Usage_GB  Churn  \n",
       "0                          17         73.36             236      0  \n",
       "1                           1         48.76             172      0  \n",
       "2                           5         85.47             460      0  \n",
       "3                           3         97.94             297      1  \n",
       "4                          19         58.14             266      0  \n",
       "5                          15         82.65             456      1  \n",
       "6                           3         73.79             269      0  \n",
       "7                           1         97.70             396      1  \n",
       "8                          10         42.45             150      1  \n",
       "9                          12         64.49             383      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer_1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>17</td>\n",
       "      <td>73.36</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer_2</td>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>48.76</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer_3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5</td>\n",
       "      <td>85.47</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer_4</td>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>3</td>\n",
       "      <td>97.94</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer_5</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>19</td>\n",
       "      <td>58.14</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer_6</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "      <td>15</td>\n",
       "      <td>82.65</td>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Customer_7</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>3</td>\n",
       "      <td>73.79</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Customer_8</td>\n",
       "      <td>67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>1</td>\n",
       "      <td>97.70</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer_9</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>10</td>\n",
       "      <td>42.45</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Customer_10</td>\n",
       "      <td>53</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>12</td>\n",
       "      <td>64.49</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Age  Gender     Location  Subscription_Length_Months  \\\n",
       "0   Customer_1   63    Male  Los Angeles                          17   \n",
       "1   Customer_2   62  Female     New York                           1   \n",
       "2   Customer_3   24  Female  Los Angeles                           5   \n",
       "3   Customer_4   36  Female        Miami                           3   \n",
       "4   Customer_5   46  Female        Miami                          19   \n",
       "5   Customer_6   67    Male     New York                          15   \n",
       "6   Customer_7   30  Female      Chicago                           3   \n",
       "7   Customer_8   67  Female        Miami                           1   \n",
       "8   Customer_9   20  Female        Miami                          10   \n",
       "9  Customer_10   53  Female  Los Angeles                          12   \n",
       "\n",
       "   Monthly_Bill  Total_Usage_GB  Churn  \n",
       "0         73.36             236      0  \n",
       "1         48.76             172      0  \n",
       "2         85.47             460      0  \n",
       "3         97.94             297      1  \n",
       "4         58.14             266      0  \n",
       "5         82.65             456      1  \n",
       "6         73.79             269      0  \n",
       "7         97.70             396      1  \n",
       "8         42.45             150      1  \n",
       "9         64.49             383      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['CustomerID'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>17</td>\n",
       "      <td>73.36</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>48.76</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5</td>\n",
       "      <td>85.47</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>3</td>\n",
       "      <td>97.94</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>Miami</td>\n",
       "      <td>19</td>\n",
       "      <td>58.14</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Houston</td>\n",
       "      <td>23</td>\n",
       "      <td>55.13</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>19</td>\n",
       "      <td>61.65</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>17</td>\n",
       "      <td>96.11</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>20</td>\n",
       "      <td>49.25</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>19</td>\n",
       "      <td>76.57</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender     Location  Subscription_Length_Months  Monthly_Bill  \\\n",
       "0       63    Male  Los Angeles                          17         73.36   \n",
       "1       62  Female     New York                           1         48.76   \n",
       "2       24  Female  Los Angeles                           5         85.47   \n",
       "3       36  Female        Miami                           3         97.94   \n",
       "4       46  Female        Miami                          19         58.14   \n",
       "...    ...     ...          ...                         ...           ...   \n",
       "99995   33    Male      Houston                          23         55.13   \n",
       "99996   62  Female     New York                          19         61.65   \n",
       "99997   64    Male      Chicago                          17         96.11   \n",
       "99998   51  Female     New York                          20         49.25   \n",
       "99999   27  Female  Los Angeles                          19         76.57   \n",
       "\n",
       "       Total_Usage_GB  Churn  \n",
       "0                 236      0  \n",
       "1                 172      0  \n",
       "2                 460      0  \n",
       "3                 297      1  \n",
       "4                 266      0  \n",
       "...               ...    ...  \n",
       "99995             226      1  \n",
       "99996             351      0  \n",
       "99997             251      1  \n",
       "99998             434      1  \n",
       "99999             173      1  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = df.drop(['Name'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Age                         100000 non-null  int64  \n",
      " 1   Gender                      100000 non-null  object \n",
      " 2   Location                    100000 non-null  object \n",
      " 3   Subscription_Length_Months  100000 non-null  int64  \n",
      " 4   Monthly_Bill                100000 non-null  float64\n",
      " 5   Total_Usage_GB              100000 non-null  int64  \n",
      " 6   Churn                       100000 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "Gender                        0\n",
       "Location                      0\n",
       "Subscription_Length_Months    0\n",
       "Monthly_Bill                  0\n",
       "Total_Usage_GB                0\n",
       "Churn                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                             int64\n",
       "Gender                         object\n",
       "Location                       object\n",
       "Subscription_Length_Months      int64\n",
       "Monthly_Bill                  float64\n",
       "Total_Usage_GB                  int64\n",
       "Churn                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.027020</td>\n",
       "      <td>12.490100</td>\n",
       "      <td>65.053197</td>\n",
       "      <td>274.393650</td>\n",
       "      <td>0.497790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.280283</td>\n",
       "      <td>6.926461</td>\n",
       "      <td>20.230696</td>\n",
       "      <td>130.463063</td>\n",
       "      <td>0.499998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>47.540000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>65.010000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>82.640000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age  Subscription_Length_Months   Monthly_Bill  \\\n",
       "count  100000.000000               100000.000000  100000.000000   \n",
       "mean       44.027020                   12.490100      65.053197   \n",
       "std        15.280283                    6.926461      20.230696   \n",
       "min        18.000000                    1.000000      30.000000   \n",
       "25%        31.000000                    6.000000      47.540000   \n",
       "50%        44.000000                   12.000000      65.010000   \n",
       "75%        57.000000                   19.000000      82.640000   \n",
       "max        70.000000                   24.000000     100.000000   \n",
       "\n",
       "       Total_Usage_GB          Churn  \n",
       "count   100000.000000  100000.000000  \n",
       "mean       274.393650       0.497790  \n",
       "std        130.463063       0.499998  \n",
       "min         50.000000       0.000000  \n",
       "25%        161.000000       0.000000  \n",
       "50%        274.000000       0.000000  \n",
       "75%        387.000000       1.000000  \n",
       "max        500.000000       1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'Age'}>,\n",
       "        <Axes: title={'center': 'Subscription_Length_Months'}>],\n",
       "       [<Axes: title={'center': 'Monthly_Bill'}>,\n",
       "        <Axes: title={'center': 'Total_Usage_GB'}>],\n",
       "       [<Axes: title={'center': 'Churn'}>, <Axes: >]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(20,20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Encoding ['Los Angeles' 'New York' 'Miami' 'Chicago' 'Houston']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Before Encoding\",df['Location'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding [2 4 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label = LabelEncoder()\n",
    "df['Location'] = label.fit_transform(df['Location'])\n",
    "print(\"After Encoding\",df['Location'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Encoding ['Male' 'Female']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Before Encoding\",df['Gender'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encoding [1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label = LabelEncoder()\n",
    "df['Gender'] = label.fit_transform(df['Gender'])\n",
    "print(\"After Encoding\",df['Gender'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>73.36</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>48.76</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>85.47</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>97.94</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>58.14</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>82.65</td>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>73.79</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>97.70</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>42.45</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>64.49</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Location  Subscription_Length_Months  Monthly_Bill  \\\n",
       "0   63       1         2                          17         73.36   \n",
       "1   62       0         4                           1         48.76   \n",
       "2   24       0         2                           5         85.47   \n",
       "3   36       0         3                           3         97.94   \n",
       "4   46       0         3                          19         58.14   \n",
       "5   67       1         4                          15         82.65   \n",
       "6   30       0         0                           3         73.79   \n",
       "7   67       0         3                           1         97.70   \n",
       "8   20       0         3                          10         42.45   \n",
       "9   53       0         2                          12         64.49   \n",
       "\n",
       "   Total_Usage_GB  Churn  \n",
       "0             236      0  \n",
       "1             172      0  \n",
       "2             460      0  \n",
       "3             297      1  \n",
       "4             266      0  \n",
       "5             456      1  \n",
       "6             269      0  \n",
       "7             396      1  \n",
       "8             150      1  \n",
       "9             383      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>73.36</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>48.76</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>85.47</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>97.94</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>58.14</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>55.13</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>61.65</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>96.11</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>49.25</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>76.57</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender  Location  Subscription_Length_Months  Monthly_Bill  \\\n",
       "0       63       1         2                          17         73.36   \n",
       "1       62       0         4                           1         48.76   \n",
       "2       24       0         2                           5         85.47   \n",
       "3       36       0         3                           3         97.94   \n",
       "4       46       0         3                          19         58.14   \n",
       "...    ...     ...       ...                         ...           ...   \n",
       "99995   33       1         1                          23         55.13   \n",
       "99996   62       0         4                          19         61.65   \n",
       "99997   64       1         0                          17         96.11   \n",
       "99998   51       0         4                          20         49.25   \n",
       "99999   27       0         2                          19         76.57   \n",
       "\n",
       "       Total_Usage_GB  Churn  \n",
       "0                 236      0  \n",
       "1                 172      0  \n",
       "2                 460      0  \n",
       "3                 297      1  \n",
       "4                 266      0  \n",
       "...               ...    ...  \n",
       "99995             226      1  \n",
       "99996             351      0  \n",
       "99997             251      1  \n",
       "99998             434      1  \n",
       "99999             173      1  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                             int64\n",
       "Gender                          int64\n",
       "Location                        int64\n",
       "Subscription_Length_Months      int64\n",
       "Monthly_Bill                  float64\n",
       "Total_Usage_GB                  int64\n",
       "Churn                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    50221\n",
       "1    49779\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Churn'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50115"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model= GradientBoostingClassifier(learning_rate=0.15,random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.4971\n",
      "Confusion matrix :\n",
      " [[6067 6046]\n",
      " [4012 3875]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55     12113\n",
      "           1       0.39      0.49      0.44      7887\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.49     20000\n",
      "weighted avg       0.52      0.50      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Log_reg = LogisticRegression(C=150, max_iter=150)\n",
    "Log_reg.fit(X_train, y_train)\n",
    "log_pred = Log_reg.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(log_pred, y_test)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(log_pred, y_test)}')\n",
    "print(f'Classification report :\\n {classification_report(log_pred, y_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.4968\n",
      "Confusion matrix :\n",
      " [[5339 5324]\n",
      " [4740 4597]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51     10663\n",
      "           1       0.46      0.49      0.48      9337\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rfc = RandomForestClassifier(n_estimators=120,criterion='gini', max_depth=15, min_samples_leaf=10, min_samples_split=5)\n",
    "Rfc.fit(X_train, y_train)\n",
    "rfc_pred = Rfc.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(rfc_pred, y_test)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(rfc_pred, y_test)}')\n",
    "print(f'Classification report :\\n {classification_report(rfc_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.50065\n",
      "Confusion matrix :\n",
      " [[5388 5296]\n",
      " [4691 4625]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.52     10684\n",
      "           1       0.47      0.50      0.48      9316\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dtc = DecisionTreeClassifier(criterion='gini', splitter='random', min_samples_leaf=15)\n",
    "Dtc.fit(X_train, y_train)\n",
    "dtc_pred = Dtc.predict(X_test)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(dtc_pred, y_test)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(dtc_pred, y_test)}')\n",
    "print(f'Classification report :\\n {classification_report(dtc_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /home/boppani/miniconda3/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/boppani/miniconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/boppani/miniconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/boppani/miniconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/boppani/miniconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/boppani/miniconda3/lib/python3.11/site-packages (from imbalanced-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 40142, 1: 39858})\n",
      "The number of classes after fit Counter({1: 5221, 0: 5096})\n"
     ]
    }
   ],
   "source": [
    "st=SMOTEENN()\n",
    "X_train_st,y_train_st = st.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sap, X_test_sap, y_train_sap, y_test_sap = train_test_split(X_train_st, y_train_st, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.5382751937984496\n",
      "Confusion matrix :\n",
      " [[445 365]\n",
      " [588 666]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.55      0.48       810\n",
      "           1       0.65      0.53      0.58      1254\n",
      "\n",
      "    accuracy                           0.54      2064\n",
      "   macro avg       0.54      0.54      0.53      2064\n",
      "weighted avg       0.56      0.54      0.54      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Dtc_sampling = DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=7, min_samples_leaf=15)\n",
    "Dtc_sampling.fit(X_train_sap, y_train_sap)\n",
    "dtc_sampling_pred = Dtc_sampling.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(dtc_sampling_pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(dtc_sampling_pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(dtc_sampling_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.6085271317829457\n",
      "Confusion matrix :\n",
      " [[614 389]\n",
      " [419 642]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      1003\n",
      "           1       0.62      0.61      0.61      1061\n",
      "\n",
      "    accuracy                           0.61      2064\n",
      "   macro avg       0.61      0.61      0.61      2064\n",
      "weighted avg       0.61      0.61      0.61      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rfc_sampling = RandomForestClassifier(n_estimators=150,criterion='gini', max_depth=15, min_samples_leaf=10, min_samples_split=6)\n",
    "Rfc_sampling.fit(X_train_sap, y_train_sap)\n",
    "rfc_sampling_pred = Rfc_sampling.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(rfc_sampling_pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(rfc_sampling_pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(rfc_sampling_pred, y_test_sap)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.48691860465116277\n",
      "Confusion matrix :\n",
      " [[314 340]\n",
      " [719 691]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.48      0.37       654\n",
      "           1       0.67      0.49      0.57      1410\n",
      "\n",
      "    accuracy                           0.49      2064\n",
      "   macro avg       0.49      0.49      0.47      2064\n",
      "weighted avg       0.55      0.49      0.50      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Log_reg_sampling = LogisticRegression(C=10, max_iter=150)\n",
    "Log_reg_sampling.fit(X_train_sap, y_train_sap)\n",
    "Log_sampling_pred = Log_reg_sampling.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(Log_sampling_pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(Log_sampling_pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(Log_sampling_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.5508720930232558\n",
      "Confusion matrix :\n",
      " [[525 419]\n",
      " [508 612]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53       944\n",
      "           1       0.59      0.55      0.57      1120\n",
      "\n",
      "    accuracy                           0.55      2064\n",
      "   macro avg       0.55      0.55      0.55      2064\n",
      "weighted avg       0.55      0.55      0.55      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train_sap, y_train_sap)\n",
    "pred = gbc.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(pred, y_test_sap)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[100, 150, 200, 250, 300],\n",
    "             'criterion': ['friedman_mse', 'squared_error', 'mse', 'mae'],\n",
    "             'min_samples_split': [2,3,4,5,6,7,8,9,10],\n",
    "             'min_samples_leaf': [1,3,5,7,9,11,13,15],'max_leaf_nodes': [3,6,8,9,12,15,18,24],\n",
    "              'max_depth': [3,5,7,9,11,13,15,17,19],\n",
    "              'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'loss': ['deviance', 'exponential']\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=0.563 total time=   2.3s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=0.554 total time=   2.6s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=0.571 total time=   2.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=0.559 total time=   2.2s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=0.569 total time=   2.1s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=17, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=17, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=17, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=17, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=17, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=5, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=5, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=5, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=5, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=5, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.593 total time=   2.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.596 total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.600 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.581 total time=   2.4s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.3, loss=exponential, max_depth=13, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=10, n_estimators=200;, score=0.615 total time=   2.2s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=4, n_estimators=250;, score=0.626 total time=   3.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=4, n_estimators=250;, score=0.632 total time=   3.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=4, n_estimators=250;, score=0.617 total time=   3.6s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=4, n_estimators=250;, score=0.618 total time=   3.7s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=4, n_estimators=250;, score=0.625 total time=   3.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=9, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=5, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=150;, score=0.506 total time=   1.4s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=150;, score=0.517 total time=   1.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=150;, score=0.521 total time=   1.4s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=150;, score=0.527 total time=   1.5s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=3, min_samples_leaf=13, min_samples_split=2, n_estimators=150;, score=0.530 total time=   1.4s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=17, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=0.590 total time=   3.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=0.602 total time=   3.4s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=0.606 total time=   3.3s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=0.588 total time=   3.6s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=9, n_estimators=250;, score=0.603 total time=   4.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=8, min_samples_leaf=1, min_samples_split=3, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.567 total time=   2.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.584 total time=   1.7s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.583 total time=   1.7s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.567 total time=   1.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=1, min_samples_split=6, n_estimators=150;, score=0.585 total time=   1.6s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=10, n_estimators=150;, score=0.528 total time=   2.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=10, n_estimators=150;, score=0.541 total time=   1.8s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=10, n_estimators=150;, score=0.530 total time=   2.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=10, n_estimators=150;, score=0.523 total time=   2.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=18, min_samples_leaf=11, min_samples_split=10, n_estimators=150;, score=0.532 total time=   2.2s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=15, min_samples_split=3, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=9, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.4, loss=exponential, max_depth=9, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=8, min_samples_leaf=7, min_samples_split=9, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=9, max_leaf_nodes=3, min_samples_leaf=3, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=8, n_estimators=250;, score=0.537 total time=   2.6s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=8, n_estimators=250;, score=0.545 total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=8, n_estimators=250;, score=0.546 total time=   2.5s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=8, n_estimators=250;, score=0.530 total time=   2.6s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=3, min_samples_leaf=9, min_samples_split=8, n_estimators=250;, score=0.553 total time=   2.3s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=0.568 total time=   1.9s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=0.561 total time=   2.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=0.561 total time=   1.9s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=0.562 total time=   1.8s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=19, max_leaf_nodes=8, min_samples_leaf=9, min_samples_split=8, n_estimators=150;, score=0.575 total time=   1.7s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=3, min_samples_split=6, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=0.558 total time=   4.4s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=0.583 total time=   4.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=0.572 total time=   3.7s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=0.561 total time=   4.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=0.598 total time=   4.4s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=13, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=9, min_samples_split=6, n_estimators=150;, score=0.540 total time=   1.8s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=9, min_samples_split=6, n_estimators=150;, score=0.555 total time=   1.9s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=9, min_samples_split=6, n_estimators=150;, score=0.546 total time=   1.9s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=9, min_samples_split=6, n_estimators=150;, score=0.541 total time=   1.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, max_leaf_nodes=9, min_samples_leaf=9, min_samples_split=6, n_estimators=150;, score=0.561 total time=   1.9s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.2, loss=deviance, max_depth=13, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.607 total time=   4.1s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.623 total time=   4.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.601 total time=   4.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.611 total time=   4.2s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=exponential, max_depth=17, max_leaf_nodes=15, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.634 total time=   4.6s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=9, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=15, max_leaf_nodes=12, min_samples_leaf=9, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.2, loss=deviance, max_depth=19, max_leaf_nodes=3, min_samples_leaf=1, min_samples_split=4, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=4, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=15, min_samples_split=8, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=0.571 total time=   2.7s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=0.591 total time=   2.5s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=0.574 total time=   2.5s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=0.570 total time=   2.6s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=9, n_estimators=150;, score=0.588 total time=   2.4s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=11, max_leaf_nodes=9, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=2, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6, n_estimators=250;, score=0.593 total time=   3.1s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6, n_estimators=250;, score=0.607 total time=   3.1s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6, n_estimators=250;, score=0.601 total time=   3.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6, n_estimators=250;, score=0.584 total time=   3.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=8, min_samples_leaf=3, min_samples_split=6, n_estimators=250;, score=0.596 total time=   3.1s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=150;, score=0.603 total time=   2.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=150;, score=0.593 total time=   2.3s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=150;, score=0.587 total time=   2.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=150;, score=0.595 total time=   2.1s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=19, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=7, n_estimators=150;, score=0.596 total time=   1.8s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=3, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=5, max_leaf_nodes=6, min_samples_leaf=11, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=2, n_estimators=150;, score=0.586 total time=   2.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=2, n_estimators=150;, score=0.599 total time=   3.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=2, n_estimators=150;, score=0.586 total time=   2.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=2, n_estimators=150;, score=0.589 total time=   2.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=19, max_leaf_nodes=24, min_samples_leaf=3, min_samples_split=2, n_estimators=150;, score=0.619 total time=   2.3s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=6, min_samples_leaf=9, min_samples_split=9, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=19, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=17, max_leaf_nodes=3, min_samples_leaf=15, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=300;, score=0.586 total time=   3.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=300;, score=0.598 total time=   3.6s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=300;, score=0.582 total time=   3.8s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=300;, score=0.598 total time=   3.6s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=6, n_estimators=300;, score=0.599 total time=   3.5s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=7, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=150;, score=0.564 total time=   2.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=150;, score=0.584 total time=   1.9s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=150;, score=0.557 total time=   2.1s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=150;, score=0.545 total time=   1.9s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=3, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=150;, score=0.582 total time=   2.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.5, loss=exponential, max_depth=15, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=13, max_leaf_nodes=18, min_samples_leaf=7, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=17, max_leaf_nodes=9, min_samples_leaf=11, min_samples_split=6, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=deviance, max_depth=17, max_leaf_nodes=12, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.3, loss=deviance, max_depth=13, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=8, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=0.625 total time=   4.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=0.627 total time=   4.2s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=0.607 total time=   4.1s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=0.598 total time=   4.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=19, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=300;, score=0.623 total time=   4.4s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.1, loss=exponential, max_depth=17, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=deviance, max_depth=5, max_leaf_nodes=8, min_samples_leaf=13, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.3, loss=exponential, max_depth=19, max_leaf_nodes=9, min_samples_leaf=13, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=exponential, max_depth=9, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=0.538 total time=   1.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=0.529 total time=   2.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=0.523 total time=   1.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=0.545 total time=   1.8s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=exponential, max_depth=7, max_leaf_nodes=6, min_samples_leaf=5, min_samples_split=2, n_estimators=150;, score=0.547 total time=   2.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.1, loss=deviance, max_depth=15, max_leaf_nodes=8, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=15, min_samples_split=7, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.05, loss=exponential, max_depth=3, max_leaf_nodes=12, min_samples_leaf=7, min_samples_split=5, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.1, loss=deviance, max_depth=7, max_leaf_nodes=15, min_samples_leaf=15, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=15, min_samples_split=8, n_estimators=150;, score=0.556 total time=   2.7s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=15, min_samples_split=8, n_estimators=150;, score=0.583 total time=   2.8s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=15, min_samples_split=8, n_estimators=150;, score=0.577 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=15, min_samples_split=8, n_estimators=150;, score=0.567 total time=   2.3s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.05, loss=exponential, max_depth=13, max_leaf_nodes=12, min_samples_leaf=15, min_samples_split=8, n_estimators=150;, score=0.576 total time=   2.3s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.05, loss=deviance, max_depth=11, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.2, loss=exponential, max_depth=5, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=9, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.05, loss=deviance, max_depth=7, max_leaf_nodes=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=0.632 total time=   4.5s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=0.657 total time=   4.9s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=0.624 total time=   4.9s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=0.633 total time=   4.8s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.4, loss=exponential, max_depth=15, max_leaf_nodes=24, min_samples_leaf=13, min_samples_split=8, n_estimators=250;, score=0.656 total time=   4.9s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=0.598 total time=   1.7s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=0.613 total time=   1.9s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=0.592 total time=   1.6s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=0.592 total time=   1.5s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.4, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=9, min_samples_split=9, n_estimators=100;, score=0.599 total time=   1.5s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=deviance, max_depth=19, max_leaf_nodes=15, min_samples_leaf=7, min_samples_split=4, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.5, loss=deviance, max_depth=19, max_leaf_nodes=18, min_samples_leaf=13, min_samples_split=7, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=squared_error, learning_rate=0.05, loss=deviance, max_depth=15, max_leaf_nodes=6, min_samples_leaf=13, min_samples_split=7, n_estimators=250;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=deviance, max_depth=19, max_leaf_nodes=9, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=deviance, max_depth=11, max_leaf_nodes=12, min_samples_leaf=11, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.3, loss=exponential, max_depth=3, max_leaf_nodes=24, min_samples_leaf=5, min_samples_split=3, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mae, learning_rate=0.5, loss=exponential, max_depth=7, max_leaf_nodes=24, min_samples_leaf=9, min_samples_split=10, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.4, loss=exponential, max_depth=17, max_leaf_nodes=24, min_samples_leaf=11, min_samples_split=2, n_estimators=150;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=mse, learning_rate=0.1, loss=deviance, max_depth=19, max_leaf_nodes=8, min_samples_leaf=15, min_samples_split=6, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=250;, score=0.603 total time=   3.6s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=250;, score=0.601 total time=   3.9s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=250;, score=0.608 total time=   3.8s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=250;, score=0.596 total time=   3.7s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=7, max_leaf_nodes=15, min_samples_leaf=13, min_samples_split=6, n_estimators=250;, score=0.624 total time=   3.8s\n",
      "[CV 1/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.555 total time=   1.2s\n",
      "[CV 2/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.563 total time=   1.1s\n",
      "[CV 3/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.567 total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.546 total time=   1.4s\n",
      "[CV 5/5] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, max_leaf_nodes=15, min_samples_leaf=3, min_samples_split=3, n_estimators=100;, score=0.562 total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;squared_error&#x27;, &#x27;mse&#x27;,\n",
       "                                                      &#x27;mae&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.4, 0.5],\n",
       "                                        &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [3, 6, 8, 9, 12, 15,\n",
       "                                                           18, 24],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 150, 200, 250,\n",
       "                                                         300]},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;squared_error&#x27;, &#x27;mse&#x27;,\n",
       "                                                      &#x27;mae&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.4, 0.5],\n",
       "                                        &#x27;loss&#x27;: [&#x27;deviance&#x27;, &#x27;exponential&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19],\n",
       "                                        &#x27;max_leaf_nodes&#x27;: [3, 6, 8, 9, 12, 15,\n",
       "                                                           18, 24],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 150, 200, 250,\n",
       "                                                         300]},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error', 'mse',\n",
       "                                                      'mae'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.2, 0.3,\n",
       "                                                          0.4, 0.5],\n",
       "                                        'loss': ['deviance', 'exponential'],\n",
       "                                        'max_depth': [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19],\n",
       "                                        'max_leaf_nodes': [3, 6, 8, 9, 12, 15,\n",
       "                                                           18, 24],\n",
       "                                        'min_samples_leaf': [1, 3, 5, 7, 9, 11,\n",
       "                                                             13, 15],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        'n_estimators': [100, 150, 200, 250,\n",
       "                                                         300]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_optm = RandomizedSearchCV(estimator=gbc, param_distributions=param_grid,n_iter=100, verbose=3)\n",
    "gbc_optm.fit(X_train_sap, y_train_sap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;, learning_rate=0.4,\n",
       "                           loss=&#x27;exponential&#x27;, max_depth=15, max_leaf_nodes=24,\n",
       "                           min_samples_leaf=13, min_samples_split=8,\n",
       "                           n_estimators=250)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;, learning_rate=0.4,\n",
       "                           loss=&#x27;exponential&#x27;, max_depth=15, max_leaf_nodes=24,\n",
       "                           min_samples_leaf=13, min_samples_split=8,\n",
       "                           n_estimators=250)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(criterion='squared_error', learning_rate=0.4,\n",
       "                           loss='exponential', max_depth=15, max_leaf_nodes=24,\n",
       "                           min_samples_leaf=13, min_samples_split=8,\n",
       "                           n_estimators=250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_optm.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.6419573643410853\n",
      "Confusion matrix :\n",
      " [[650 356]\n",
      " [383 675]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1006\n",
      "           1       0.65      0.64      0.65      1058\n",
      "\n",
      "    accuracy                           0.64      2064\n",
      "   macro avg       0.64      0.64      0.64      2064\n",
      "weighted avg       0.64      0.64      0.64      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc_tunning = GradientBoostingClassifier(learning_rate=0.5, loss='exponential', max_depth=11,\n",
    "                           max_leaf_nodes=18, min_samples_leaf=5,\n",
    "                           min_samples_split=6, n_estimators=250)\n",
    "gbc_tunning.fit(X_train_sap, y_train_sap)\n",
    "pred = gbc_tunning.predict(X_test_sap)\n",
    "\n",
    "print(f'Accuracy score : {accuracy_score(pred, y_test_sap)}')\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(pred, y_test_sap)}')\n",
    "print(f'Classification report :\\n {classification_report(pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.49806201550387597\n",
      "Confusion matrix :\n",
      " [[935 938]\n",
      " [ 98  93]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.64      1873\n",
      "           1       0.09      0.49      0.15       191\n",
      "\n",
      "    accuracy                           0.50      2064\n",
      "   macro avg       0.50      0.49      0.40      2064\n",
      "weighted avg       0.83      0.50      0.60      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multilayer perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=1000)\n",
    "mlp.fit(X_train_sap, y_train_sap)\n",
    "mlp_pred = mlp.predict(X_test_sap)\n",
    "#accuracy\n",
    "print(f'Accuracy score : {accuracy_score(mlp_pred, y_test_sap)}')\n",
    "#confusion matrix\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(mlp_pred, y_test_sap)}')\n",
    "#report\n",
    "print(f'Classification report :\\n {classification_report(mlp_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_sap, y_train_sap)\n",
    "knn_pred = knn.predict(X_test_sap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.7790697674418605\n",
      "Confusion matrix :\n",
      " [[790 213]\n",
      " [243 818]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78      1003\n",
      "           1       0.79      0.77      0.78      1061\n",
      "\n",
      "    accuracy                           0.78      2064\n",
      "   macro avg       0.78      0.78      0.78      2064\n",
      "weighted avg       0.78      0.78      0.78      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "print(f'Accuracy score : {accuracy_score(knn_pred, y_test_sap)}')\n",
    "#confusion matrix\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(knn_pred, y_test_sap)}')\n",
    "#report\n",
    "print(f'Classification report :\\n {classification_report(knn_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.4738372093023256\n",
      "Confusion matrix :\n",
      " [[175 228]\n",
      " [858 803]]\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.43      0.24       403\n",
      "           1       0.78      0.48      0.60      1661\n",
      "\n",
      "    accuracy                           0.47      2064\n",
      "   macro avg       0.47      0.46      0.42      2064\n",
      "weighted avg       0.66      0.47      0.53      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train_sap, y_train_sap)\n",
    "svm_pred = svm.predict(X_test_sap)\n",
    "#accuracy\n",
    "print(f'Accuracy score : {accuracy_score(svm_pred, y_test_sap)}')\n",
    "#confusion matrix\n",
    "print(f'Confusion matrix :\\n {confusion_matrix(svm_pred, y_test_sap)}')\n",
    "#report\n",
    "print(f'Classification report :\\n {classification_report(svm_pred, y_test_sap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename  =  'trained_model.sav'\n",
    "pickle.dump(knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the saved model \n",
    "loaded_model = pickle.load(open('trained_model.sav', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for Unseen Data: [0]\n"
     ]
    }
   ],
   "source": [
    "CustomerID = int(input(\"Enter CustomerID: \"))\n",
    "Name = input(\"Enter Name: \")\n",
    "\n",
    "location = input(\"Enter Location: \")\n",
    "age = int(input(\"Enter Age: \"))\n",
    "gender = input(\"Enter Gender: \")\n",
    "Subscription_Length_Months = float(input(\"Subscription_Length_Months: \"))\n",
    "Monthly_Bill = float(input(\"Monthly_Bill: \"))\n",
    "Total_Usage_GB = float(input(\"Total_Usage_GB: \"))\n",
    "\n",
    "user_data  = {\n",
    "    'CustomerID': [CustomerID],\n",
    "    'Name': [Name],\n",
    "    'Age': [age],\n",
    "    'Gender' : [gender],\n",
    "    'Location': [location],\n",
    "    'Subscription_Length_Months': [Subscription_Length_Months],\n",
    "    'Monthly_Bill': [Monthly_Bill],\n",
    "    'Total_Usage_GB': [Total_Usage_GB]\n",
    "}\n",
    "\n",
    "new_data = pd.DataFrame(user_data)\n",
    "new_data = new_data.drop(['CustomerID' ,'Name'], axis=1)\n",
    "new_data['Location'] = label.fit_transform(new_data['Location'])\n",
    "new_data['Gender'] = label.fit_transform(new_data['Gender'])\n",
    "\n",
    "knn_pred_unseen = knn.predict(new_data)\n",
    "print(\"Prediction for Unseen Data:\", knn_pred_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
